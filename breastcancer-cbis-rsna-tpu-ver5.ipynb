{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install numpy==1.15\n!pip install pydicom\n# !pip install pylibjpeg \n!pip install pylibjpeg-libjpeg\n!pip install python-gdcm","metadata":{"_uuid":"4fecedaf-f781-4c0e-9393-8139c159fc04","_cell_guid":"a2e4037e-65d0-4499-ab80-d1dc749f933f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:40.019289Z","iopub.execute_input":"2023-09-29T01:16:40.020034Z","iopub.status.idle":"2023-09-29T01:16:54.020798Z","shell.execute_reply.started":"2023-09-29T01:16:40.019979Z","shell.execute_reply":"2023-09-29T01:16:54.019539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **This project use two datasets, the first one is CBIS-DDSM contains jpeg images and the second one is RSNA contains .dcm images**","metadata":{"_uuid":"b736f9d7-e72c-4565-b138-40e3f813fdf6","_cell_guid":"3263565d-49e2-4d70-b7f6-5ad1176dce0b","trusted":true}},{"cell_type":"code","source":"# imports the torch_xla package\nimport torch_xla\ntorch_xla.__version__\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.experimental.pjrt_backend \nimport torch_xla.experimental.pjrt as pjrt\nimport torch_xla.test.test_utils as test_utils\n\nimport torch.distributed as dist\nfrom torch.nn.parallel import DistributedDataParallel as DDP","metadata":{"_uuid":"98f1840c-17c7-4dc9-9dec-d5ba893f4686","_cell_guid":"5098cb02-3328-4a7d-a9b6-b3eb856386e1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:54.022775Z","iopub.execute_input":"2023-09-29T01:16:54.023070Z","iopub.status.idle":"2023-09-29T01:16:56.279883Z","shell.execute_reply.started":"2023-09-29T01:16:54.023041Z","shell.execute_reply":"2023-09-29T01:16:56.278532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pydicom\n# import pylibjpeg\nfrom pydicom import dcmread\nimport numpy as np\nimport pandas as pd\nimport torch\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n#import dicomsdl as dicoml\n# import pydicom\nimport re\n# from joblib import Parallel, delayed\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\n# from PIL import Image\nimport cv2\nimport gc\nimport glob\n# import importlib\nimport os\n# import joblib\nimport time\nfrom torchvision.io import read_image\nimport torch.nn as nn\nfrom torchvision.models import  densenet161, DenseNet161_Weights, efficientnet_v2_l, EfficientNet_V2_L_Weights, convnext_base, ConvNeXt_Base_Weights\nfrom torchvision.models.convnext import CNBlock\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport torch.optim as optim","metadata":{"_uuid":"35796135-b081-4a0a-a00e-35ce066377fd","_cell_guid":"9b2d36ae-71c6-4183-b1c8-9eb111ed6c96","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:56.281499Z","iopub.execute_input":"2023-09-29T01:16:56.281934Z","iopub.status.idle":"2023-09-29T01:16:57.363760Z","shell.execute_reply.started":"2023-09-29T01:16:56.281903Z","shell.execute_reply":"2023-09-29T01:16:57.362668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Path for saving weights\nweight_path_save = '/kaggle/working/'","metadata":{"_uuid":"71331510-19f3-49e1-ae47-6d7c07a48a86","_cell_guid":"65880805-0dab-4a94-a2db-0d688ecb3ece","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:57.365184Z","iopub.execute_input":"2023-09-29T01:16:57.365605Z","iopub.status.idle":"2023-09-29T01:16:57.369705Z","shell.execute_reply.started":"2023-09-29T01:16:57.365576Z","shell.execute_reply":"2023-09-29T01:16:57.368731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!printenv","metadata":{"_uuid":"098cbb9e-3b3d-4fa4-85c0-ee5a99f698cc","_cell_guid":"d8d4d2b9-ebed-482f-bc49-a3e8b97d42c4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:57.372638Z","iopub.execute_input":"2023-09-29T01:16:57.372953Z","iopub.status.idle":"2023-09-29T01:16:58.414941Z","shell.execute_reply.started":"2023-09-29T01:16:57.372927Z","shell.execute_reply":"2023-09-29T01:16:58.413569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flags = {}\nflags['number_epochs'] = 70\nflags['model_name'] = 'convnext_base'\nflags['batch_size'] = 16\nflags['learning_rate'] = 0.01\nflags['weight_decay'] = 0.005\nflags['num_workers'] = 8\nflags['final_freeze'] = 17\nflags['img_standard_H'] = 850\nflags['img_standard_W'] = 512\n\nflags['agumentation'] = {}\nflags['agumentation']['img_H'] = 360\nflags['agumentation']['img_W'] = 224\nflags['agumentation']['scale_min'] = 0.3\nflags['agumentation']['scale_max'] = 1.2\nflags['agumentation']['ratio_min'] = 1.1\nflags['agumentation']['ratio_max'] = 1.7\nflags['agumentation']['alpha'] = 180.0 # float\nflags['agumentation']['sigma'] = 8.0 # float\nflags['agumentation']['mean'] = 0 # float\nflags['agumentation']['std'] = 0.4 # float\nflags['use_crop'] = False","metadata":{"execution":{"iopub.status.busy":"2023-09-29T01:16:58.416577Z","iopub.execute_input":"2023-09-29T01:16:58.416892Z","iopub.status.idle":"2023-09-29T01:16:58.427256Z","shell.execute_reply.started":"2023-09-29T01:16:58.416862Z","shell.execute_reply":"2023-09-29T01:16:58.426410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Processing first dataset**","metadata":{"_uuid":"23004a9a-bf59-41c5-b2d8-fd6fafe5901a","_cell_guid":"c97a43ab-7fe5-4dc1-8540-6069cd651711","trusted":true}},{"cell_type":"code","source":"# Path meta data infor\ninfor_path = '/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/dicom_info.csv'\ncalc_case_train_path = '/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_train_set.csv'\ncalc_case_test_path = '/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_test_set.csv'\nmass_case_train_path = '/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_train_set.csv'\nmass_case_test_path = '/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_test_set.csv'","metadata":{"_uuid":"c28d1498-9f48-4370-8c80-226bd0f737db","_cell_guid":"87c5fd0c-fc9d-4dc3-b030-9f398234e82c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:58.428571Z","iopub.execute_input":"2023-09-29T01:16:58.428946Z","iopub.status.idle":"2023-09-29T01:16:58.439229Z","shell.execute_reply.started":"2023-09-29T01:16:58.428917Z","shell.execute_reply":"2023-09-29T01:16:58.438262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read master infor file\nmaster = pd.read_csv(infor_path)\n# train cata\ncalc_case_train = pd.read_csv(calc_case_train_path)\nmass_case_train = pd.read_csv(mass_case_train_path)\n# test data\ncalc_case_test = pd.read_csv(calc_case_test_path)\nmass_case_test = pd.read_csv(mass_case_test_path)","metadata":{"_uuid":"52c8d0fb-a7a1-4d7a-afb4-d5dab3617cf6","_cell_guid":"b6c1a391-176f-4456-8b25-4f2b1456074f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:58.440469Z","iopub.execute_input":"2023-09-29T01:16:58.440786Z","iopub.status.idle":"2023-09-29T01:16:58.640048Z","shell.execute_reply.started":"2023-09-29T01:16:58.440761Z","shell.execute_reply":"2023-09-29T01:16:58.638938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove row contains NaN\nmaster.dropna(axis = 0,subset=['Laterality'] ,inplace = True)\nmaster.head(10)","metadata":{"_uuid":"19ccbd6a-ed32-4d52-8e20-1645ee1620f7","_cell_guid":"ccc877fc-d785-4e53-b5a7-b54dbf6caa4a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:58.641382Z","iopub.execute_input":"2023-09-29T01:16:58.641668Z","iopub.status.idle":"2023-09-29T01:16:58.688294Z","shell.execute_reply.started":"2023-09-29T01:16:58.641643Z","shell.execute_reply":"2023-09-29T01:16:58.687412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove row contains 16 bit image only\nmaster = master[master['BitsAllocated'] == 16]\nmaster.head(10)","metadata":{"_uuid":"c2ed2225-2967-4559-9e21-837e9da7db20","_cell_guid":"f293d199-2d17-4132-915c-c12b313d79c3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:58.689695Z","iopub.execute_input":"2023-09-29T01:16:58.690050Z","iopub.status.idle":"2023-09-29T01:16:58.724535Z","shell.execute_reply.started":"2023-09-29T01:16:58.690019Z","shell.execute_reply":"2023-09-29T01:16:58.723633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get patient id in master dataframe\ndef get_patient_id(row):\n    element = re.split(\"-|_\",row['PatientID'])\n    patient_id_list = element[2:4]\n    patient_id_list.insert(1,'_')\n    return (\"\".join(patient_id_list) , element[0], element[1])\n\nmaster[['PatientID','tumor_type','data_type']] = master.apply(lambda x: get_patient_id(x),axis = 1,result_type = 'expand')\nmaster[['PatientID','tumor_type','data_type']]","metadata":{"_uuid":"d5f8818f-ebb9-45c6-ac06-f9b6fff1854e","_cell_guid":"04b4df44-244d-4e2f-9d0a-12189d77e3d6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:58.725701Z","iopub.execute_input":"2023-09-29T01:16:58.725981Z","iopub.status.idle":"2023-09-29T01:16:59.122534Z","shell.execute_reply.started":"2023-09-29T01:16:58.725956Z","shell.execute_reply":"2023-09-29T01:16:59.121574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Edit file path of jpg image\ndef replace_file_path(row):\n    new_path = row.replace('CBIS-DDSM','/kaggle/input/cbis-ddsm-breast-cancer-image-dataset')\n    return new_path\n    \nmaster['image_path'] = master['image_path'].apply(lambda x: replace_file_path(x))\nmaster['image_path']","metadata":{"_uuid":"8b629868-03d5-4441-b6be-e1dfc3e6c7bd","_cell_guid":"d272a99d-6143-457a-a4ae-cf588f253813","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.123805Z","iopub.execute_input":"2023-09-29T01:16:59.124107Z","iopub.status.idle":"2023-09-29T01:16:59.138379Z","shell.execute_reply.started":"2023-09-29T01:16:59.124081Z","shell.execute_reply":"2023-09-29T01:16:59.137446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only select full mammogram images, remove cropped images\nmaster_full = master[master['SeriesDescription'] == 'full mammogram images']\nmaster_full","metadata":{"_uuid":"90fa4360-95d4-47a5-a4de-89a2b7c88b9d","_cell_guid":"daa82142-2c85-4b1a-a37f-e578b43ae016","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.139853Z","iopub.execute_input":"2023-09-29T01:16:59.140288Z","iopub.status.idle":"2023-09-29T01:16:59.186148Z","shell.execute_reply.started":"2023-09-29T01:16:59.140252Z","shell.execute_reply":"2023-09-29T01:16:59.185274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only select cropped images, remove full mammogram images\nmaster_crop = master[master['SeriesDescription'] == 'cropped images']\nmaster_crop","metadata":{"_uuid":"a543b40b-6f63-4345-817a-a1ce583b56c5","_cell_guid":"76aea1d4-cb94-4a2e-9284-ecd11f604510","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.191786Z","iopub.execute_input":"2023-09-29T01:16:59.192091Z","iopub.status.idle":"2023-09-29T01:16:59.239285Z","shell.execute_reply.started":"2023-09-29T01:16:59.192064Z","shell.execute_reply":"2023-09-29T01:16:59.238197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select few columns only\nmaster_full = master_full[['image_path', 'Laterality', 'PatientID', 'PatientOrientation','tumor_type','data_type']]\nmaster_full.reset_index(inplace= True, drop = True)\nmaster_full.head(10)","metadata":{"_uuid":"aec5c840-5a20-41b0-89d7-fe1250389065","_cell_guid":"62e215bb-47ee-4517-bdf1-460968c41bea","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.240796Z","iopub.execute_input":"2023-09-29T01:16:59.241125Z","iopub.status.idle":"2023-09-29T01:16:59.258131Z","shell.execute_reply.started":"2023-09-29T01:16:59.241096Z","shell.execute_reply":"2023-09-29T01:16:59.257057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select few columns only\nmaster_crop = master_crop[['image_path', 'Laterality', 'PatientID', 'PatientOrientation','tumor_type','data_type']]\nmaster_crop.reset_index(inplace= True, drop = True)\nmaster_crop.head(10)","metadata":{"_uuid":"a68fbf5f-303d-4edb-81fa-bfb4e5d9de4f","_cell_guid":"da3cdba0-8013-442f-b412-5b2bc2b5fd6c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.259615Z","iopub.execute_input":"2023-09-29T01:16:59.260057Z","iopub.status.idle":"2023-09-29T01:16:59.280293Z","shell.execute_reply.started":"2023-09-29T01:16:59.260023Z","shell.execute_reply":"2023-09-29T01:16:59.279214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_key(curr_row):\n    # get image id\n    img_id = re.split(\"/\",curr_row['image_path'])[-2]\n    \n    # Laterality\n    Later = 'RIGHT' if curr_row['Laterality'] == 'R' else 'LEFT'\n    \n    # concat to make key\n    match_key = curr_row['tumor_type']+'-'+curr_row['data_type']+'_'+ curr_row['PatientID']+'_'+Later+'_'+\\\n                curr_row['PatientOrientation']+'_'+img_id\n    return match_key\n###### make key\nmaster_full['match_key'] =  master_full.apply(lambda x: make_key(x),axis = 1)\n\nmaster_crop['match_key'] =  master_crop.apply(lambda x: make_key(x),axis = 1)","metadata":{"_uuid":"adccb006-c1c0-4029-82ac-503bb3482609","_cell_guid":"807b342f-93cd-494a-a5be-0502793b76b2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.281735Z","iopub.execute_input":"2023-09-29T01:16:59.282114Z","iopub.status.idle":"2023-09-29T01:16:59.595333Z","shell.execute_reply.started":"2023-09-29T01:16:59.282081Z","shell.execute_reply":"2023-09-29T01:16:59.594220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# n = 19\n# print('ID: ',master['PatientID'][n], ',tumor: ', master['tumor_type'][n], master['image_path'][n])\n# img = cv2.imread(master['image_path'][n])\n# plt.imshow(img)\n# plt.show()","metadata":{"_uuid":"b9b06ddf-1442-4456-95a6-e64c4f4d61cc","_cell_guid":"07a8e7b7-0aef-4a45-b448-a9694fb6c98d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.596606Z","iopub.execute_input":"2023-09-29T01:16:59.596914Z","iopub.status.idle":"2023-09-29T01:16:59.601441Z","shell.execute_reply.started":"2023-09-29T01:16:59.596887Z","shell.execute_reply":"2023-09-29T01:16:59.600528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Processing mass case file .csv (train case)\nmass_case_train = mass_case_train[['breast_density','pathology','image file path','cropped image file path']]\nmass_case_train.head(5)","metadata":{"_uuid":"ae94e937-813b-4bc2-8251-98e6bb6da511","_cell_guid":"5613d4a2-1233-41b5-965a-a6475c6dd183","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.602713Z","iopub.execute_input":"2023-09-29T01:16:59.603007Z","iopub.status.idle":"2023-09-29T01:16:59.621426Z","shell.execute_reply.started":"2023-09-29T01:16:59.602981Z","shell.execute_reply":"2023-09-29T01:16:59.620336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_keys_in_mass_case(curr_row):\n    # get image id for full image\n    elements = re.split(\"/\",curr_row['image file path'])\n    img_di = elements[-2]\n    \n    # get image id for cropped image\n    elements_2 = re.split(\"/\",curr_row['cropped image file path'])\n    img_di_2 = elements_2[-2]\n    \n    return elements[0]+'_'+img_di, elements_2[0][0:-2]+'_'+img_di_2\n\nmass_case_train[['match_key1','match_key2']] =  mass_case_train.apply(lambda x: make_keys_in_mass_case(x),axis = 1, result_type= 'expand')\nmass_case_train.head(5)","metadata":{"_uuid":"77fc1000-2ccd-44fa-878a-73342acbde9e","_cell_guid":"8ab36c11-dc4c-40fa-bccc-e60088d58048","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.622732Z","iopub.execute_input":"2023-09-29T01:16:59.623054Z","iopub.status.idle":"2023-09-29T01:16:59.733935Z","shell.execute_reply.started":"2023-09-29T01:16:59.623026Z","shell.execute_reply":"2023-09-29T01:16:59.732946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Processing mass case file .csv (test case)\nmass_case_test = mass_case_test[['breast_density','pathology','image file path','cropped image file path']]\nmass_case_test[['match_key1','match_key2']] =  mass_case_test.apply(lambda x: make_keys_in_mass_case(x),axis = 1, result_type = 'expand')\nmass_case_test.head(5)","metadata":{"_uuid":"d07519eb-8be6-4446-8ab4-0d94d241bb8c","_cell_guid":"91821df7-8d11-4406-9830-8fbfc4add7d5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.735197Z","iopub.execute_input":"2023-09-29T01:16:59.735483Z","iopub.status.idle":"2023-09-29T01:16:59.778089Z","shell.execute_reply.started":"2023-09-29T01:16:59.735460Z","shell.execute_reply":"2023-09-29T01:16:59.777077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Processing calc case file .csv (train case)\ncalc_case_train = calc_case_train[['breast density','pathology','image file path','cropped image file path']]\ncalc_case_train.head(5)","metadata":{"_uuid":"a86a53c6-89e7-4d02-bf7d-94a077c378d8","_cell_guid":"eae2b6e8-9c79-41eb-b88e-109894e8f3d4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.779562Z","iopub.execute_input":"2023-09-29T01:16:59.779916Z","iopub.status.idle":"2023-09-29T01:16:59.794326Z","shell.execute_reply.started":"2023-09-29T01:16:59.779885Z","shell.execute_reply":"2023-09-29T01:16:59.793312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_key2_in_calc_case(curr_row):\n    # get image id for full image\n    elements = re.split(\"/\",curr_row['image file path'])\n    img_di = elements[-2]\n    \n    # get image id for cropped image\n    elements_2 = re.split(\"/\",curr_row['cropped image file path'])\n    img_di_2 = elements_2[-2]\n    \n    return elements[0]+'_'+img_di, elements_2[0][0:-2]+'_'+img_di_2\n\ncalc_case_train[['match_key1','match_key2']] =  calc_case_train.apply(lambda x: make_key2_in_calc_case(x),axis = 1,result_type = 'expand')\ncalc_case_train.rename(columns = {'breast density':'breast_density'}, inplace = True)\ncalc_case_train.head(5)","metadata":{"_uuid":"2fdaa29a-f6ef-429b-8480-9ec6d2622ec9","_cell_guid":"f9b834a9-2ee1-4d84-a752-150a673b4b17","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:16:59.795610Z","iopub.execute_input":"2023-09-29T01:16:59.795967Z","iopub.status.idle":"2023-09-29T01:17:00.085747Z","shell.execute_reply.started":"2023-09-29T01:16:59.795938Z","shell.execute_reply":"2023-09-29T01:17:00.084824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Processing calc case file .csv (test case)\ncalc_case_test = calc_case_test[['breast density','pathology','image file path','cropped image file path']]\ncalc_case_test.rename(columns = {'breast density':'breast_density'}, inplace = True)\ncalc_case_test[['match_key1','match_key2']] =  calc_case_test.apply(lambda x: make_key2_in_calc_case(x),axis = 1,result_type = 'expand')\ncalc_case_test.rename(columns = {'breast density':'breast_density'}, inplace = True)\ncalc_case_test.head(5)","metadata":{"_uuid":"68f75737-34f6-4893-8871-740b6c379846","_cell_guid":"123190e0-d717-4306-b51d-7f2af98cfc06","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:00.087054Z","iopub.execute_input":"2023-09-29T01:17:00.087358Z","iopub.status.idle":"2023-09-29T01:17:00.128323Z","shell.execute_reply.started":"2023-09-29T01:17:00.087332Z","shell.execute_reply":"2023-09-29T01:17:00.127448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge case file into master dataframe\nother_concat = pd.concat([mass_case_train, mass_case_test, calc_case_train, calc_case_test])\nother_concat_key1 = other_concat.drop(columns = 'match_key2',inplace = False)\nother_concat_key1.drop_duplicates(subset = 'match_key1', inplace = True)\nother_concat_key1.reset_index(inplace= True, drop = True)\nprint(\"length of other key1: \", len(other_concat_key1))\nother_concat_key2 = other_concat.drop(columns = 'match_key1', inplace = False)\nother_concat_key2.drop_duplicates(subset = 'match_key2', inplace = True)\nother_concat_key2.reset_index(inplace= True, drop = True)\nprint(\"length of other key2: \", len(other_concat_key2))\n\n\nmaster_full = master_full.merge(other_concat_key1,how = 'left', left_on = 'match_key',copy = False, right_on = 'match_key1', validate = '1:m')\nmaster_crop = master_crop.merge(other_concat_key2,how = 'left' ,left_on = 'match_key', right_on = 'match_key2', validate = '1:m')","metadata":{"_uuid":"60826017-d138-4635-8102-8787a75eb12e","_cell_guid":"02fb1ce2-0ede-436e-a0d7-edd46fafef48","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:00.129627Z","iopub.execute_input":"2023-09-29T01:17:00.129987Z","iopub.status.idle":"2023-09-29T01:17:00.172148Z","shell.execute_reply.started":"2023-09-29T01:17:00.129954Z","shell.execute_reply":"2023-09-29T01:17:00.171299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"master_crop","metadata":{"_uuid":"040e46e3-f545-4d1f-a934-f37b252b5788","_cell_guid":"ca4ca6ca-153f-4586-9709-409c78654e3b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:00.173315Z","iopub.execute_input":"2023-09-29T01:17:00.173589Z","iopub.status.idle":"2023-09-29T01:17:00.195791Z","shell.execute_reply.started":"2023-09-29T01:17:00.173564Z","shell.execute_reply":"2023-09-29T01:17:00.194926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = 100\nprint('ID: ',master_crop['PatientID'][n], ',tumor: ', master_crop['tumor_type'][n], master_crop['image_path'][n])\nimg = cv2.imread(master_crop['image_path'][n])\n\nplt.imshow(img)\nplt.show()","metadata":{"_uuid":"0fee68ea-5f42-4efe-a7ed-b8aeb3259707","_cell_guid":"7d919930-c3b1-4489-84b4-f0930cbd8cf8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:00.197070Z","iopub.execute_input":"2023-09-29T01:17:00.197408Z","iopub.status.idle":"2023-09-29T01:17:00.526134Z","shell.execute_reply.started":"2023-09-29T01:17:00.197380Z","shell.execute_reply":"2023-09-29T01:17:00.525204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"master_full['image_type'] = 'full'\nmaster_full","metadata":{"_uuid":"e305a80a-e4af-49f1-b42a-d61ef1985514","_cell_guid":"8ba666ae-3c7c-4272-8ce9-af980bcde03f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:00.527353Z","iopub.execute_input":"2023-09-29T01:17:00.527641Z","iopub.status.idle":"2023-09-29T01:17:00.553956Z","shell.execute_reply.started":"2023-09-29T01:17:00.527615Z","shell.execute_reply":"2023-09-29T01:17:00.553017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"master_full = master_full[['image_path','Laterality','PatientID', 'PatientOrientation', 'tumor_type','data_type','breast_density','pathology']]\nmaster_full['image_type'] = 'full'\nmaster_crop = master_crop[['image_path','Laterality','PatientID', 'PatientOrientation', 'tumor_type','data_type','breast_density','pathology']]\nmaster_crop['image_type'] = 'crop'\n# final dataframe master\nfinal_master_dataset_1 = 0\nif flags['use_crop']:\n    final_master_dataset_1 = pd.concat([master_full, master_crop])\nelse:\n    final_master_dataset_1 = master_full\n    \nfinal_master_dataset_1.sample(frac = 1.0, axis= 0, random_state = 1000)\nfinal_master_dataset_1","metadata":{"_uuid":"f8dc2ede-2814-480f-817d-966225d4d59f","_cell_guid":"3fc5a018-b644-48e7-a54f-2308fbce1cb9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:00.555340Z","iopub.execute_input":"2023-09-29T01:17:00.555974Z","iopub.status.idle":"2023-09-29T01:17:00.587860Z","shell.execute_reply.started":"2023-09-29T01:17:00.555940Z","shell.execute_reply":"2023-09-29T01:17:00.586966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make label base benign and malignant\ndef create_label(value):\n    if value == 'MALIGNANT':\n        return 1\n    if value == 'BENIGN' or value == 'BENIGN_WITHOUT_CALLBACK':\n        return 0\n\nfinal_master_dataset_1['label'] = final_master_dataset_1['pathology'].apply(lambda x: create_label(x))\nfinal_master_dataset_1","metadata":{"_uuid":"e2b42227-5955-4050-ac25-c1667590e34e","_cell_guid":"4e2e37ba-a562-4ab8-8bbb-317ecb7537d7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:00.589200Z","iopub.execute_input":"2023-09-29T01:17:00.589546Z","iopub.status.idle":"2023-09-29T01:17:00.617261Z","shell.execute_reply.started":"2023-09-29T01:17:00.589514Z","shell.execute_reply":"2023-09-29T01:17:00.616393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training set\nfinal_train_dataset_1= final_master_dataset_1[final_master_dataset_1['data_type']=='Training']\nfinal_train_dataset_1 = final_train_dataset_1.reset_index(drop = True)\n# train_master = train_master.head(2)\n# test set\nfinal_test_dataset_1= final_master_dataset_1[final_master_dataset_1['data_type']=='Test']\nfinal_test_dataset_1 = final_test_dataset_1.reset_index(drop = True)\n# val_master = val_master.head(2)\nprint(\"Length of training set of dataset 1: \", len(final_train_dataset_1))\nprint(\"Length of test set of dataset 1: \", len(final_test_dataset_1))","metadata":{"_uuid":"b2cdb2d7-6cc2-4b54-ac37-4087603e2af3","_cell_guid":"d7555d57-1f99-41d0-8476-545e67e23816","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:00.618364Z","iopub.execute_input":"2023-09-29T01:17:00.618930Z","iopub.status.idle":"2023-09-29T01:17:00.631759Z","shell.execute_reply.started":"2023-09-29T01:17:00.618899Z","shell.execute_reply":"2023-09-29T01:17:00.630724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_train_dataset_1","metadata":{"execution":{"iopub.status.busy":"2023-09-29T01:17:00.633099Z","iopub.execute_input":"2023-09-29T01:17:00.633498Z","iopub.status.idle":"2023-09-29T01:17:00.657058Z","shell.execute_reply.started":"2023-09-29T01:17:00.633467Z","shell.execute_reply":"2023-09-29T01:17:00.656209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # unit test dataset 1\n# from pydicom import dcmread\n# import numpy as np\n# idx = 2\n# sample_path = final_train_dataset_1.at[idx, \"image_path\"]\n# print(sample_path,\", view: \", final_train_dataset_1.at[idx, \"Laterality\"])\n\n# tensor = read_image(sample_path)\n# # transform instance\n# aug = transforms.Compose([transforms.RandomResizedCrop(size = (flags['img_H'],flags['img_W']), scale=(0.3, 1.2), ratio=(1.1,1.7) ,antialias = True),\n#                           transforms.ElasticTransform(alpha = 150.0, sigma = 8.0),\n#                           transforms.RandomAutocontrast(),\n#                           transforms.Normalize((0), (0.4))\n#                           ])\n# tensor = aug(tensor.float())\n# plt.imshow(tensor.numpy().squeeze(), cmap = 'gray')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T01:17:00.658254Z","iopub.execute_input":"2023-09-29T01:17:00.658576Z","iopub.status.idle":"2023-09-29T01:17:00.666404Z","shell.execute_reply.started":"2023-09-29T01:17:00.658548Z","shell.execute_reply":"2023-09-29T01:17:00.665653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Processing second dataset**\n\ndont use test data because it doesnot contain labels","metadata":{"_uuid":"7feb1e73-555f-4733-bcbc-2120e086aec9","_cell_guid":"fa7cf195-c393-4a26-b1f5-e1d0fbe2b236","trusted":true}},{"cell_type":"code","source":"meta_dataset_2 = pd.read_csv(\"/kaggle/input/rsna-breast-cancer-detection/train.csv\")\nmeta_dataset_2 = meta_dataset_2.sample(frac = 1.0, random_state = 300)\nmeta_dataset_2 = meta_dataset_2.head(6000)\nprint(\"Lenght of dataset 2: \",len(meta_dataset_2))","metadata":{"_uuid":"a1ca4bee-eaab-4f0a-8366-82fb9ca9d792","_cell_guid":"71c5ffd3-db66-4bef-869c-9f82da3965ab","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:00.667403Z","iopub.execute_input":"2023-09-29T01:17:00.667761Z","iopub.status.idle":"2023-09-29T01:17:00.778713Z","shell.execute_reply.started":"2023-09-29T01:17:00.667736Z","shell.execute_reply":"2023-09-29T01:17:00.777867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_full_path(current_row):\n    return \"/kaggle/input/rsna-breast-cancer-detection/train_images/\" + \\\n                    str(current_row[\"patient_id\"]) + \"/\" + str(current_row[\"image_id\"]) + \".dcm\"\n    \nmeta_dataset_2[\"full_path\"] = meta_dataset_2.apply(lambda x: make_full_path(x), axis = 1)\nmeta_dataset_2 = meta_dataset_2[[\"full_path\",\"cancer\",\"laterality\",\"view\"]]","metadata":{"_uuid":"96cd70e1-4c03-45dd-8db6-e3a8a16be0bf","_cell_guid":"15ce2193-b39c-4ec0-9766-8ede09fc13a8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:00.780050Z","iopub.execute_input":"2023-09-29T01:17:00.780617Z","iopub.status.idle":"2023-09-29T01:17:00.894289Z","shell.execute_reply.started":"2023-09-29T01:17:00.780585Z","shell.execute_reply":"2023-09-29T01:17:00.893485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If later == L -> Width reduce N\n# If later == R --> 0 increase N\ndef find_offset(curr_row, default_offset: int = 800):\n    if curr_row[\"laterality\"] == \"L\":\n        return 0, default_offset\n    elif curr_row[\"laterality\"] == \"R\":\n        return default_offset, 0\n    \nmeta_dataset_2[[\"start_width\",\"end_width\"]] = meta_dataset_2.apply(lambda x: find_offset(x), axis = 1, result_type = 'expand' )\nmeta_dataset_2.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T01:17:00.895397Z","iopub.execute_input":"2023-09-29T01:17:00.895695Z","iopub.status.idle":"2023-09-29T01:17:01.179423Z","shell.execute_reply.started":"2023-09-29T01:17:00.895668Z","shell.execute_reply":"2023-09-29T01:17:01.178447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_dataset_2[[\"start_width\",\"end_width\"]].isna().values.any()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T01:17:01.180774Z","iopub.execute_input":"2023-09-29T01:17:01.181056Z","iopub.status.idle":"2023-09-29T01:17:01.188195Z","shell.execute_reply.started":"2023-09-29T01:17:01.181031Z","shell.execute_reply":"2023-09-29T01:17:01.187398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffle and split datasource 2 into train and test\nmeta_dataset_2_train = meta_dataset_2.head(len(meta_dataset_2)//2)\nmeta_dataset_2_test = meta_dataset_2.tail(len(meta_dataset_2)//2)","metadata":{"_uuid":"c74f6b68-b4e0-4b2b-a3ab-db5027a4cd4f","_cell_guid":"00ad8484-d96d-46cf-bf08-f6343055b69e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:01.189410Z","iopub.execute_input":"2023-09-29T01:17:01.189754Z","iopub.status.idle":"2023-09-29T01:17:01.198359Z","shell.execute_reply.started":"2023-09-29T01:17:01.189723Z","shell.execute_reply":"2023-09-29T01:17:01.197629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Intergrate dataframe of dataset 2 into dataframe of dataset 1 by *.concat()* method","metadata":{"_uuid":"ff8ec5d9-7890-4775-b92f-a0486a9d1482","_cell_guid":"168a3bea-5dc6-4a59-98dd-a1482d4929da","trusted":true}},{"cell_type":"code","source":"meta_dataset_2_train","metadata":{"execution":{"iopub.status.busy":"2023-09-29T01:17:01.199440Z","iopub.execute_input":"2023-09-29T01:17:01.199744Z","iopub.status.idle":"2023-09-29T01:17:01.221964Z","shell.execute_reply.started":"2023-09-29T01:17:01.199717Z","shell.execute_reply":"2023-09-29T01:17:01.221218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"integrated_train_df = pd.concat([final_train_dataset_1,meta_dataset_2_train],ignore_index = True)\n#integrated_train_df = final_train_dataset_1\nintegrated_train_df = integrated_train_df.sample(frac = 1.0, random_state = 500)\nintegrated_train_df = integrated_train_df.fillna(0)\nintegrated_train_df.reset_index(inplace = True)\n\nintegrated_test_df = pd.concat([final_test_dataset_1,meta_dataset_2_test],ignore_index = True)\nintegrated_test_df = integrated_test_df.sample(frac = 1.0, random_state = 300)\nintegrated_test_df = integrated_test_df.fillna(0)\nintegrated_test_df.reset_index(inplace = True)","metadata":{"_uuid":"6f1eaa9b-46e6-4a6b-813d-5345e236219a","_cell_guid":"36b749b9-aec7-448d-b2e9-78a69471fb06","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:01.223020Z","iopub.execute_input":"2023-09-29T01:17:01.223516Z","iopub.status.idle":"2023-09-29T01:17:01.252003Z","shell.execute_reply.started":"2023-09-29T01:17:01.223486Z","shell.execute_reply":"2023-09-29T01:17:01.251303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# integrated_train_df = integrated_train_df.head(200)","metadata":{"_uuid":"fdf7e564-7755-4380-8d29-2533f8c8dbd8","_cell_guid":"1ca50871-110f-45bb-b8b3-b95bcaa6f958","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:01.258695Z","iopub.execute_input":"2023-09-29T01:17:01.259035Z","iopub.status.idle":"2023-09-29T01:17:01.262963Z","shell.execute_reply.started":"2023-09-29T01:17:01.259005Z","shell.execute_reply":"2023-09-29T01:17:01.262071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # unit test dataset 2\n# from pydicom import dcmread\n# import numpy as np\n# idx = 48946\n# sample_path = meta_dataset_2_train.at[idx, \"full_path\"]\n# print(sample_path,\", view: \", meta_dataset_2_train.at[idx, \"laterality\"])\n# dcm_file = dcmread(sample_path, force = True)\n# image_array = dcm_file.pixel_array   #Output from extract dicom is uint16\n# #image_array = image_array*255/32767  # scale from range (0,32767) to (0,255) dtype = float64\n# image_array = image_array.astype(np.float32)\n# H, W = image_array.shape\n# image_array = image_array[200: H-200 ,0 + meta_dataset_2_train.at[idx, \"start_width\"]: W + \\\n#                           meta_dataset_2_train.at[idx, \"end_width\"]] \n# print(image_array.shape)\n# plt.imshow(image_array.squeeze(), cmap = 'gray')\n# plt.show()\n\n# # transform instance\n# aug = transforms.Compose([transforms.RandomResizedCrop(size = (flags['img_H'],flags['img_W']), \n#                                                        scale=(0.3, 1.2), ratio=(1.1,1.7) ,antialias = True),\n#                           transforms.ElasticTransform(alpha = 150.0, sigma = 8.0),\n#                           transforms.RandomAutocontrast(),\n#                           transforms.Normalize((0), (0.4))\n#                           ])\n\n# image_array = np.expand_dims(image_array,axis = 0)\n# tensor = torch.tensor(image_array).float() # cast to torch tensor dtype float32\n# tensor = aug(tensor)\n# plt.imshow(tensor.numpy().squeeze(), cmap = 'gray')\n# plt.show()","metadata":{"_uuid":"934ac6b5-4bc8-4a70-a7d2-576aecb104c1","_cell_guid":"57ffdc69-17fc-4c69-93a4-798ed9f75814","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:01.264012Z","iopub.execute_input":"2023-09-29T01:17:01.264326Z","iopub.status.idle":"2023-09-29T01:17:01.274444Z","shell.execute_reply.started":"2023-09-29T01:17:01.264298Z","shell.execute_reply":"2023-09-29T01:17:01.273709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ### Implement Cutout in nn.Module ###\n# import torch.nn as nn\n# from typing import List, Tuple\n# class Cutout(nn.Module):\n#     def __init__(self, \n#                  num_holes: int, \n#                  holes_size: Tuple[int, int], \n#                  max_topleft_position_ratio: Tuple[float, float],\n#                  min_topleft_position_ratio: Tuple[float, float]\n#                 ) -> None:\n#         self.num_holes = num_holes\n#         self.holes_size = holes_size\n#         self.max_topleft_position_ratio = max_topleft_position_ratio\n#         self.min_topleft_position_ratio = min_topleft_position_ratio\n#         super(Cutout, self).__init()\n        \n#     def forward(self, x):\n#         assert x.ndim == 3, \"Input dim of data must be 3\"\n#         input_shape = x.shape\n#         mask = torch.ones((input_shape[1], input_shape[2])) # 2 dimentional tensor\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-29T01:17:01.275420Z","iopub.execute_input":"2023-09-29T01:17:01.275682Z","iopub.status.idle":"2023-09-29T01:17:01.287728Z","shell.execute_reply.started":"2023-09-29T01:17:01.275659Z","shell.execute_reply":"2023-09-29T01:17:01.286983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######### Define class of dataset to read images and labels\nclass MyDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Class for loading images and labels that collected from 2 dataset sources\n    \"\"\"\n    def __init__(self,integrated_dataframe, flags, dataset_type: str):\n        self.integrated_dataframe = integrated_dataframe\n        self.flags = flags\n        if dataset_type == \"training\":\n            self._full_img_transform = transforms.Compose([transforms.Resize((self.flags['img_standard_H'],self.flags['img_standard_W']), \n                                                                             antialias = True)\n                                                            ])\n        elif dataset_type == \"validation\":\n            self._full_img_transform = transforms.Compose([transforms.Resize((self.flags['agumentation']['img_H'],self.flags['agumentation']['img_W']), \n                                                                             antialias = True)\n                                                            ])\n    \n#     def _crop_img_transform(self, input_img):\n#         return transforms.Compose([transforms.Resize((self.flags['img_H'],self.flags['img_W']), antialias = True)\n#                                   ])(input_img)\n    \n    def __len__(self):\n        return len(self.integrated_dataframe)\n    \n    def _path_to_arrary(self,idx):\n        dcm_file = dcmread(self.integrated_dataframe['full_path'][idx], force = True)\n        image_array = dcm_file.pixel_array\n        image_array = image_array.astype(np.float32)\n        \n        H, W = image_array.shape\n        image_array = image_array[150: H-150 ,int(self.integrated_dataframe[\"start_width\"][idx]): W - int(self.integrated_dataframe[\"end_width\"][idx]) ] \n        image_array = np.expand_dims(image_array,axis = 0)\n        return image_array\n    \n    def __getitem__(self,idx):\n        # get image from image path/full path\n        temp_img_dir = self.integrated_dataframe['image_path'][idx] # from dataset 1\n        if temp_img_dir != 0:   # case of dataset 1\n            image = read_image(temp_img_dir)\n            image = self._full_img_transform(image.float())\n            image = image.expand(3,*image.shape[1:])\n            # get label\n            label = torch.tensor(0).to(torch.long) if self.integrated_dataframe['label'][idx] == 0 else \\\n                                                            torch.tensor(1).to(torch.long)\n            return  image, label\n            \n            \n        else: # case of dataset 2\n            image = torch.tensor(self._path_to_arrary(idx))  # cast to torch tensor dtype float32\n            image = self._full_img_transform(image.float())\n            image = image.expand(3,*image.shape[1:])\n            label = torch.tensor(0).to(torch.long) if self.integrated_dataframe['cancer'][idx] == 0 else \\\n                                                            torch.tensor(1).to(torch.long)\n            return  image, label","metadata":{"_uuid":"58e295ac-42f2-4382-b028-cc60b78d16b8","_cell_guid":"20bec20e-dc11-4763-a1f2-2fda5377868e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:01.288799Z","iopub.execute_input":"2023-09-29T01:17:01.289216Z","iopub.status.idle":"2023-09-29T01:17:01.306303Z","shell.execute_reply.started":"2023-09-29T01:17:01.289183Z","shell.execute_reply":"2023-09-29T01:17:01.305571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef make_model(model_str_name: str, flags: dict ,final_freeze_layer_order: int = 17): \n    assert model_str_name in [\"densenet\",\"efficientnet\", \"convnext_base\"], \"Invalid model name\" \n    \n    ### Augmentation Model ###\n    aug_model = nn.Sequential(\n                transforms.RandomResizedCrop(size = (flags['agumentation']['img_H'],flags['agumentation']['img_W']), \n                                                                    scale=(flags['agumentation']['scale_min'], flags['agumentation']['scale_max']), \n                                                                    ratio=(flags['agumentation']['ratio_min'],flags['agumentation']['ratio_max']) ,antialias = True),\n                transforms.ElasticTransform(alpha = flags['agumentation']['alpha'], sigma = flags['agumentation']['sigma']),\n                transforms.RandomAutocontrast(),\n                transforms.Normalize((flags['agumentation']['mean']), (flags['agumentation']['std']))\n                )\n    for para in aug_model.parameters():\n        para.requires_grad = False\n    \n    if model_str_name == \"densenet\":\n        classifier_model = densenet161(weights = DenseNet161_Weights.IMAGENET1K_V1, progress = False)  \n        classifier_model.classifier = torch.nn.Sequential(\n                                    nn.Linear(2208, 1024),\n                                    nn.ReLU(inplace = True),\n                                    nn.Dropout(inplace = True),\n                                    nn.Linear(1024,2)\n                                    )\n        for params in classifier_model.parameters():\n                params.requires_grad = False\n        # Fine-tuning model\n        for order, child in enumerate(classifier_model.children()):\n            if order == 0 and isinstance(child,torch.nn.Sequential):\n                for sub_order, sub_layer in enumerate(child):\n                    if sub_order > final_freeze_layer_order:\n                        for param in sub_layer.parameters():\n                            param.requires_grad = True\n            else:\n                for params in child.parameters():\n                    params.requires_grad = True\n        return classifier_model, aug_model\n    elif model_str_name == \"efficientnet\":\n        classifier_model = efficientnet_v2_l(weights = EfficientNet_V2_L_Weights.IMAGENET1K_V1, progress = False) \n        classifier_model.fc = torch.nn.Sequential(\n                                    nn.Linear(1280, 512),\n                                    nn.ReLU(inplace = True),\n                                    nn.Dropout(inplace = True),\n                                    nn.Linear(512,2)\n                                    )\n        for params in classifier_model.parameters():\n                params.requires_grad = False\n                # Fine-tuning model\n        for order, child in enumerate(classifier_model.children()):\n            if order == 0 and isinstance(child,torch.nn.Sequential):\n                for sub_order, sub_layer in enumerate(child):\n                    if sub_order > final_freeze_layer_order:\n                        for param in sub_layer.parameters():\n                            param.requires_grad = True\n            else:\n                for params in child.parameters():\n                    params.requires_grad = True\n        return classifier_model, aug_model\n    \n    elif model_str_name == \"convnext_base\":\n        classifier_model = convnext_base(weights = ConvNeXt_Base_Weights.IMAGENET1K_V1, progress = False) \n        classifier_model.classifier.append(torch.nn.Linear(in_features = 1000, out_features = 2, bias = True))\n        # Set all grad to False first\n        for params in classifier_model.parameters():\n            params.requires_grad = False\n        \n        # Finetuning\n        for order,structure in enumerate(classifier_model.children()):\n            if order == 0: # denoted as (features)\n                # counting layer\n                count_layer = []\n                for seq_order, seq in enumerate(structure):\n                    if not isinstance(seq,torch.nn.Sequential):\n                        count_layer.append(1)\n                    else:\n                        count_cnb = 0\n                        for cnb_block in seq.children():\n                            if isinstance(cnb_block, CNBlock):\n                                count_cnb += 1\n                        if count_cnb == 0:\n                            count_layer.append(1)\n                        else:\n                            count_layer.append(count_cnb)\n\n                # Determine index of star unfreeze layer\n                stop_index, cnb_stop_id = None, None\n                for idx,element in enumerate(count_layer):\n                    if idx != 0:\n                        sum = 0\n                        for ind in range(idx+1):\n                            sum = sum + count_layer[ind]\n                        if sum >= final_freeze_layer_order:\n                            stop_index = idx\n                            cnb_stop_id = count_layer[idx] - (sum - final_freeze_layer_order)-1\n                            break\n                # set requires grad\n                for seq_order, seq in enumerate(structure):\n                    if seq_order == stop_index:\n                        if count_layer[seq_order] == cnb_stop_id + 1:\n                            continue\n                        else:\n                            for cnb_id, cnb in enumerate(seq.children()):\n                                if cnb_id > cnb_stop_id:\n                                    for params in cnb.parameters():\n                                        params.requires_grad = True\n\n                    elif seq_order > stop_index:\n                        for params in seq.parameters():\n                            params.requires_grad = True\n\n            else:\n                for params in structure.parameters():\n                    params.requires_grad = True\n        return classifier_model, aug_model","metadata":{"_uuid":"6664aa22-b712-4fcb-8df3-01145fb7d517","_cell_guid":"1b9412e8-f60e-4a2b-b04a-9c589a9c6b5e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:01.307351Z","iopub.execute_input":"2023-09-29T01:17:01.307631Z","iopub.status.idle":"2023-09-29T01:17:01.337409Z","shell.execute_reply.started":"2023-09-29T01:17:01.307606Z","shell.execute_reply":"2023-09-29T01:17:01.336664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _training_loop(input_model,augmentation_model,train_data_loader,train_length:int, optimizer,scheduler,loss_fn, device, scaled_data_step:int =1):\n    train_loss = torch.tensor(0.0, dtype = torch.float32,device = device)\n    train_corrects = torch.tensor(0, dtype = torch.int16,device = device)\n    stop_step = train_length//scaled_data_step\n    for step, (inputs, labels) in enumerate(train_data_loader):\n        xm.master_print(\"Step: \",step)\n        if step == stop_step:\n            break\n        else: \n            # clean gradient\n            optimizer.zero_grad()\n            # apply augmentation \n            inputs = augmentation_model(inputs)\n            # Make predictions for this batch\n            outputs = input_model(inputs)\n            # Compute the loss and its gradients\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            # Adjust learning weights\n            xm.optimizer_step(optimizer)  # for pjrt, for ddp use optimizer.step() xm.mark_step()\n            train_loss = train_loss + loss\n            # for monitor\n            class_pred = torch.argmax(outputs,1)\n            train_corrects = train_corrects + torch.div(torch.eq(class_pred,labels).sum(),labels.shape[0])\n    \n    scheduler.step()\n    # in epoch to summary\n    train_loss = torch.div(train_loss,torch.div(train_length,scaled_data_step))\n    train_corrects = torch.div(train_corrects,torch.div(train_length,scaled_data_step))\n    return train_loss, train_corrects\n    \ndef _validation_loop(model,val_data_loader, val_length, loss_fn, device, scaled_data_step:int = 1):\n    with torch.no_grad():\n        val_loss = torch.tensor(0.0, dtype = torch.float32,device = device)\n        val_corrects = torch.tensor(0, dtype = torch.int16,device = device)\n        stop_step = val_length//scaled_data_step\n        for i, (test_inputs, test_labels) in enumerate(val_data_loader):\n            xm.master_print(\"val step: \", i)\n            if i == stop_step:\n                break\n            else:\n                test_outputs = model(test_inputs)\n                current_val_loss = loss_fn(test_outputs, test_labels)\n                val_loss += current_val_loss\n\n                # for monitor\n                val_class_pred = torch.argmax(test_outputs,1)\n                val_corrects = val_corrects + torch.div(torch.eq(val_class_pred,test_labels).sum(),test_labels.shape[0])\n        # in epoch to summary\n        val_loss = torch.div(val_loss,torch.div(val_length,scaled_data_step))\n        val_corrects = torch.div(val_corrects, torch.div(val_length,scaled_data_step))\n    return val_loss, val_corrects\n    \ndef training_pipeline(classifier_model,\n                     augmentation_model,\n                     num_epochs: int, \n                     learning_rate: float, \n                     weight_decay: float,\n                     train_loader: pl.MpDeviceLoader, \n                     val_loader: pl.MpDeviceLoader,\n                     train_length: int,\n                     val_length: int,\n                     device):\n    \n    # Define optimizer\n    loss_fn = torch.nn.CrossEntropyLoss()\n    optimizer = optim.SGD(classifier_model.parameters(), lr= learning_rate*xm.xrt_world_size(), momentum=0.9, weight_decay = weight_decay)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = learning_rate*xm.xrt_world_size()*5,\n                                                steps_per_epoch = train_length,\n                                                epochs = num_epochs,\n                                                anneal_strategy='cos')\n    train_loss_list = []\n    train_acc_list = []\n    val_loss_list = []\n    val_acc_list = []\n    augmentation_model.eval()\n    for epoch in range(num_epochs):\n        classifier_model.train()\n        train_loss, train_acc = _training_loop(classifier_model,augmentation_model,train_loader,train_length,optimizer,scheduler,loss_fn, device)\n\n        # reduce tensor's values before appending to master\n        train_loss, train_acc = xm.all_reduce(reduce_type = \"sum\", inputs = [train_loss, train_acc], scale = 0.125, groups = [[0,1,2,3,4,5,6,7]])\n        xm.master_print(\"Lets wait\")\n        xm.wait_device_ops()\n        xm.master_print('Epoch {} after reduce, train loss\" {}, train accuracy\" {}, current process: {} \\n'.format(epoch,train_loss, train_acc, xm.get_ordinal()))  #testing\n        train_loss_list.append(train_loss.clone().detach().cpu().numpy())\n        train_acc_list.append(train_acc.clone().detach().cpu().numpy())\n        \n        \n        # Validation process \n        classifier_model.eval()\n        val_loss, val_acc = _validation_loop(classifier_model,val_loader, val_length, loss_fn, device)\n        # reduce tensor's values before appending to master\n        val_loss, val_acc = xm.all_reduce(reduce_type = \"sum\", inputs = [val_loss, val_acc], scale = 0.125, groups = [[0,1,2,3,4,5,6,7]])\n        xm.master_print(\"Lets wait for validation\")\n#         xm.wait_device_ops()\n        xm.master_print('Epoch {} after reduce, val loss\" {}, val accuracy\" {}, current process: {} \\n'.format(epoch,val_loss, val_acc, xm.get_ordinal()))  #testing\n        \n        val_loss_list.append(val_loss.clone().detach().cpu().numpy())\n        val_acc_list.append(val_acc.clone().detach().cpu().numpy())\n        \n        # save model's weights (condition: compare loss in epoch level)\n#         if  val_running_loss > min(total_val_loss)*1.1 :\n#             print('Saving model with val loss of {:.3f}'.format(val_running_loss))\n#             torch.save(classifier_model.state_dict(), weight_path_save+str(epoch)+'_checkpoint_weights'+model_name)\n    \n    # Save at end of epochs\n#     torch.save(classifier_model.state_dict(), weight_path_save+'final_checkpoint_weights'+model_name)\n    return train_loss_list, train_acc_list, val_loss_list, val_acc_list","metadata":{"_uuid":"00c26834-418f-4ac5-a56b-986981e4d3d9","_cell_guid":"f78a41d5-7d62-4c5c-b3a6-a6db419040d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:01.338538Z","iopub.execute_input":"2023-09-29T01:17:01.338864Z","iopub.status.idle":"2023-09-29T01:17:01.368168Z","shell.execute_reply.started":"2023-09-29T01:17:01.338836Z","shell.execute_reply":"2023-09-29T01:17:01.367420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_result(train_loss_list,train_acc_list,val_loss_list, val_acc_list, model_name: str):\n    \n    # draw plot\n    plt.plot(train_acc_list, color = 'blue',label = \"training accuracy\")\n    plt.plot(val_acc_list, color = 'orange',label = \"validation accuracy\")\n    plt.ylabel(\"Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n    plt.title(\"Training and validation accuracy of \"+ model_name)\n    plt.show()\n    \n    plt.plot(train_loss_list, color = 'blue',label = \"training loss\")\n    plt.plot(val_loss_list, color = 'orange',label = \"validation loss\")\n    plt.ylabel(\"Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n    plt.title(\"Training and validation loss of \"+ model_name)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T01:17:01.369246Z","iopub.execute_input":"2023-09-29T01:17:01.369549Z","iopub.status.idle":"2023-09-29T01:17:01.382131Z","shell.execute_reply.started":"2023-09-29T01:17:01.369521Z","shell.execute_reply":"2023-09-29T01:17:01.381411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _map_fn(rank, flags):\n    # Device configuration\n    device = xm.xla_device()\n    dist.init_process_group('xla',init_method='pjrt://')\n    \n    # make model and transfer to device\n    model, aug_model = make_model(model_str_name = flags['model_name'], flags = flags,final_freeze_layer_order = flags['final_freeze'])\n    model = model.to(device)\n    aug_model = aug_model.to(device)\n    pjrt.broadcast_master_param(model)\n    pjrt.broadcast_master_param(aug_model)\n    # create sampler\n    number_replicas = xm.xrt_world_size()\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n                                                      training_data,\n                                                      num_replicas=number_replicas,\n                                                      rank=rank, \n                                                      shuffle=True)\n    val_sampler = torch.utils.data.distributed.DistributedSampler(\n                                                      validation_data,\n                                                      num_replicas=number_replicas,\n                                                      rank=rank, \n                                                      shuffle=True)\n    train_dataloader = DataLoader(training_data, \n                                  batch_size= flags['batch_size'], \n                                  sampler=train_sampler, \n                                  shuffle = False,\n                                  num_workers = flags['num_workers'],\n                                  drop_last = True)\n    val_dataloader = DataLoader(validation_data, \n                                batch_size= flags['batch_size'], \n                                sampler=val_sampler,\n                                shuffle = False,\n                                num_workers = flags['num_workers'],\n                                drop_last = True)\n    # Distributed loader to device\n    xla_train_loader = pl.MpDeviceLoader(train_dataloader, device)\n    xla_val_loader = pl.MpDeviceLoader(val_dataloader, device)\n    train_length = len(train_dataloader)\n    val_length = len(val_dataloader)\n    train_loss, train_acc, val_loss, val_acc = training_pipeline(model,\n                                                                 aug_model,\n                                                                 num_epochs = flags['number_epochs'], \n                                                                 learning_rate = flags['learning_rate'], \n                                                                 weight_decay = flags['weight_decay'],\n                                                                 train_loader = xla_train_loader, \n                                                                 val_loader = xla_val_loader,\n                                                                 train_length = train_length,\n                                                                 val_length = val_length,\n                                                                 device = device)\n    # Visualization\n    if xm.is_master_ordinal():\n        draw_result( train_loss, train_acc, val_loss, val_acc, flags['model_name'])\n\n# Main process\nif __name__ == '__main__':\n    os.environ.pop('TPU_PROCESS_ADDRESSES')\n    os.environ.pop('CLOUD_TPU_TASK_ID')\n    os.environ['PJRT_DEVICE'] = 'TPU'\n    ########### Create dataset ############\n    torch.manual_seed(300)\n    train_df = integrated_train_df.head(int(len(integrated_train_df)*0.7))\n    val_df = integrated_train_df.tail(len(integrated_train_df) - len(train_df))\n    val_df.reset_index(drop = True, inplace = True)\n    training_data = MyDataset(train_df, flags, \"training\")\n    validation_data = MyDataset(val_df, flags, \"validation\")\n    \n    test_data = MyDataset(integrated_test_df, flags, \"validation\")\n    \n    if torch.distributed.is_available():\n        #Note: in interactive notebooks, you must use start_method='fork'\n        xmp.spawn(_map_fn, args=(flags,), start_method='fork')\n    else:\n        print(\"No distributed\")","metadata":{"_uuid":"81f92873-31f2-4af1-9327-97d4ff58a982","_cell_guid":"41b0112d-ee6f-4a97-9a8c-1483387d7a40","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-29T01:17:01.383126Z","iopub.execute_input":"2023-09-29T01:17:01.383442Z"},"trusted":true},"execution_count":null,"outputs":[]}]}